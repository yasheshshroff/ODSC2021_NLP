{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6w6mhl0GOjk"
   },
   "source": [
    "## Disaster or not: Text Classification using TFIDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "FLs8SMhVGOjl",
    "outputId": "53131bfb-b59f-49bb-9ff9-4ec4b2d9c9fb"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/ravi-ilango/acm-dec-2020-nlp/blob/main/lab2/disaster_data.zip?raw=true -O disaster_data.zip\n",
    "    \n",
    "!unzip disaster_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./disaster_data/train.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QX8SHDxIanDm",
    "outputId": "0f77d1c2-41fe-4098-bac3-0a0860555e5c"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# queries are stored in the variable query_text\n",
    "# correct intent labels are stored in the variable labels\n",
    "#\n",
    "query_text = pd.read_csv('./disaster_data/train.csv').text.values\n",
    "labels = pd.read_csv('./disaster_data/train.csv').target.values\n",
    "\n",
    "query_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "QGBCR4tyTpff",
    "outputId": "01c61a91-19e1-418c-ad69-b8fc74d2c25e"
   },
   "outputs": [],
   "source": [
    "plt.hist(labels)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('count')\n",
    "plt.title('target distribution')\n",
    "plt.xticks(np.arange(len(np.unique(labels))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "query_train, query_test, y_train, y_test = train_test_split(query_text, labels, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Vectorize the text document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "ngram_range = (1,2)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, \n",
    "                             stop_words='english', \n",
    "                             max_features=150)\n",
    "\n",
    "X_train = vectorizer.fit_transform(query_train).toarray()\n",
    "X_test = vectorizer.transform(query_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Fit a classifier using the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Calculate Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print (f\"Test Accuracy = {(y_pred == y_test).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5ZsT6bGOjw"
   },
   "source": [
    "### Check Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2pnJ1xjGOkl"
   },
   "outputs": [],
   "source": [
    "def predict(model, query_txt):\n",
    "    x = vectorizer.transform([query_txt]).toarray()\n",
    "    pred = model.predict(x)\n",
    "    if pred[0] == 1:\n",
    "        print (\"Disaster\")\n",
    "    else:\n",
    "        print (\"Not a disaster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vEpMVvuGOkn"
   },
   "outputs": [],
   "source": [
    "predict (clf, \"Forest fire near La Ronge Sask. Canada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clf, \"The weather is awesome\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "bert_lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
